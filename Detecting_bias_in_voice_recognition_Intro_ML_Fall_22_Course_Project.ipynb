{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymLuex86v22i"
      },
      "source": [
        "# Detecting bias in voice recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbLN_GTewojk"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckwpHejMxLP-"
      },
      "source": [
        "---\n",
        "\n",
        "For this project, we are expected to take voice samples from people of various demographics, and process their voices into DeepSpeech that will predict what is being said to see the effects of voice recognition bias. DeepSpeech is a speech-to-text engine that allows predictions of an audio sample transcription to be made in real-time as the file is running [1]. The purpose of this is to predict what is being said in the audio files themselves and see if the file's annotation and the prediction match up. However, because of the nature of a particular project being overly biased towards specific demographics by means of relative numbers, the DeepSpeech engine will become biased towards that demographic. So if there is a voice sample from a person who isn't the main demographic of voice samples, the character error rate of that person's voice sample will be higher than the main demographic's.\n",
        "\n",
        "The DeepSpeech project can have a wide variety of applications that can be put to use, such as the auto-closed captioning system used for YouTube [3], and potentially for hearing assistence speech-to-text for deaf people. Using DeepSpeech in comparison to other voice recognition engines since it is simpler compared to other engines such as Wav2Vec and Whisper, it's prediction results that are somewhere in between the two without having to predict the stutter of the audio sample [2] [3]. This can mean that with relatively little requirements on its part, it can somewhat accurately predict what the speaker has said in the audio sample. However, as with all prediction-based algorithms, there is always some amount of bias being fed into the algorithm, and this is nothing new to prediction-based systems. \n",
        "\n",
        "To address this issue, or at least find out what are the general trends and biases that these engines have, a company known as Artie Inc. has developed what they called the Artie Bias Corpus. This dataset, which is shown in [6], takes audio samples from various people of different demographics, such as races, gender, age groups and even accents and compare them against the DeepSpeech algorithm in order to see how biased the results are. For this to happen, people from five main demographics voluntarily participated in this study to record their own audio samples (over 1700 in total) and submit them to Artie Inc. and then measure the various error rates between various combinations of those demographics to see where the bias is most apparent [7]. The prediction for what is being said in the audio is transcribed in the artie-bias-corpus.tsv file within the data directory and then predictions are made with three different engines (Google, DeepSpeech, and Amazon) with various accents implemented and then the predictions are made within their respective .tsv files, with various levels of bias and success [6][7].\n",
        "\n",
        "Challenges that are faced when traditionally using speech to text services such as Google and Alexa voice services is that they're only tested with overwhelmingly white American accents, hence why there's a whole lot of bias present in voice recognition [4] [5]. In the Artie Bias Corpus report, both of their algorithms were put to the test along with the DeepSpeech algorithm which was, at the start of the report, possibly unbiased initially. As more annotations and voice samples are fed into the system, the algorithm is more influenced by the samples, and in most cases, they seem to be male American accents in the Artie Bias Corpus voice samples linked in the repository of [6]. By comparing the predictions of the Google and Amazon voice engines in comparison to the DeepSpeech engine, Indian accents get funkier results from the same voice sample in comparison to British and American accents, which seem to be pretty similar and produce less error. All three engines have a bias towards American male accents, although the DeepSpeech engine seems to produce no noticeable gender bias in comparison to Google's engine in the figure below [4] [6] [7, Fig. 4].\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw_SbVAXB7qj"
      },
      "source": [
        "![firefox_cH0kmXubts.png](data:image/png;base64,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)\n",
        "\n",
        "Image is Figure 4 from [7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1cI2uX2TgYs"
      },
      "source": [
        "---\n",
        "\n",
        "In comparison to the pre-existing work over on GitHub found on [6], we are including new voice samples found from Professor Lectures on YouTube and then seeing what the predictions made from DeepSpeech turn out to be. We would have to create a spreadsheet document and would eventually turn that into a .tsv file, as we would compare the actual sentence in comparison to DeepSpeech's prediction. To do this, we would have to collect audio samples from these YouTube videos, and the methodology to what kind of information we have collected here goes as follows for accents: 2 American, 2 Scottish, 2 British, 2 Australian, and 2 Indian. Gender wouldn't matter too much as the figure above shows that the bias isn't as pronounced as it was with Google and Amazon's engine. By contrast, the bias this system had towards American English accents in comparison to Indian English accents can very much not be ignored [7, Fig. 5]. We must then see the outputs of the predictions to see how close they were to the actual sentence being said in the first couple of seconds in the video to determine the gender and racial bias and confirm or reject our claim.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WYBXd7AXQAY"
      },
      "source": [
        "![firefox_e6ljBcK2CE.png](data:image/png;base64,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)\n",
        "\n",
        "Image is Figure 5 from [7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdf28bFUwqNh"
      },
      "source": [
        "## Working with the existing code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwlq7EVQzC5T"
      },
      "source": [
        "---\n",
        "To begin with, we have to adapt the code from the GitHub repository of the Artie Bias Corpus, which is shown here in [6].\n",
        "\n",
        "Summary of the code:\n",
        "The Artie Bias Corpus measures the bias of a speech model by comparing annotations made by the Artie Bias Corpus contributors,which are treated as the ground truth, to the annotations made by the speech model. The bias is defined as the Levenshtein distance between the Artie annotations and the model's annotations divided by the number of words present in the Artie annotations. The Levenshtein distance measures the similarity between two strings; in this codebase the Levenstein distance is computed by comparing two words, and increasing the distance by 1 whenever words in the same position do not match.\n",
        "\n",
        "The script starts by calling the detect_bias Function. This function takes the artie annotations, annotations made by one to two speech models, and one to two demographics present in the Artie annotation's demographics. It calls print_args_error() if any of the above parameters are missing, and then calls check_args to check the parameters for invalid values. The number of models and demographics in the parameters are then checked, depeneding on if two models and one demographic or if one model or two demographics were input, the script utilizes two different functions, compare_two_models(), and detect_bias_in_one_model respectively.\n",
        " \n",
        "Before compare_two_models() or detect_bias_in_one_model() is called in either scenario, get_merged_df() is called to check the Artie and speech model annotation files for the correct structure. After verifying the structure of both files, the annotations present on both files are inserted on to a new merged dataframe. The Levenhstein distance and error rate between the annotations are then calculated and inserted into the dataframe.\n",
        "\n",
        "compare_two_models() prints the error rate for both models on the single demographic; detect_bias_in_one_model does something similar where the error rate is printed for two demographics on the same model.\n",
        "\n",
        "When adapting the code to colab, the main method present in the original detect_bias.py file was changed to the detect_bias for convenience. Because of this, we made several variables in the main method global. For our claim validation since we are using our own samples, we will be inputting our own hand annotations rather than the Artie annotatons for the first parameter in detect_bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcmmZXUWrrKn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvGbnCNA_OhQ",
        "outputId": "3c496aa9-e1f1-4a2b-b8a0-5c9ffd555009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSeUE4sFX7LK",
        "outputId": "3ffb7b7b-a5d1-4332-ca47-f143516ed12c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/tsv_files/deepSpeech.tsv', '/content/tsv_files/ourAnnot.tsv']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gdown\n",
        "gdown.download_folder(\"https://drive.google.com/drive/folders/14aFeXQiSKKgQEg3r48fhd0VdKjxnDnrn?usp=share_link\", quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h3fbVQjYhlJ",
        "outputId": "e7a2336d-e6e1-4fdf-d1b4-b2c651365fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Nrijy9P9grZ"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.special as special\n",
        "from scipy import stats\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-S6TjTjPIHAX"
      },
      "outputs": [],
      "source": [
        "def levenshtein(a,b):\n",
        "    '''\n",
        "    The following code is from: http://hetland.org/coding/python/levenshtein.py\n",
        "    This is a straightforward implementation of a well-known algorithm, and thus\n",
        "    probably shouldn't be covered by copyright to begin with. But in case it is,\n",
        "    the author (Magnus Lie Hetland) has, to the extent possible under law,\n",
        "    dedicated all copyright and related and neighboring rights to this software\n",
        "    to the public domain worldwide, by distributing it under the CC0 license,\n",
        "    version 1.0. This software is distributed without any warranty. For more\n",
        "    information, see <http://creativecommons.org/publicdomain/zero/1.0>\n",
        "    \n",
        "    Calculates the Levenshtein distance between a and b.\n",
        "    '''\n",
        "    n, m = len(a), len(b)\n",
        "    if n > m:\n",
        "        # Make sure n <= m, to use O(min(n,m)) space\n",
        "        a, b = b, a\n",
        "        n, m = m, n\n",
        "\n",
        "    current = list(range(n+1))\n",
        "    for i in range(1, m+1):\n",
        "        previous, current = current, [i]+[0]*n\n",
        "        for j in range(1, n+1):\n",
        "            add, delete = previous[j]+1, current[j-1]+1\n",
        "            change = previous[j-1]\n",
        "            if a[j-1] != b[i-1]:\n",
        "                change = change + 1\n",
        "            current[j] = min(add, delete, change)\n",
        "\n",
        "    return current[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qVAc1kK7IIcb"
      },
      "outputs": [],
      "source": [
        "def get_error_rate(item, unit):\n",
        "    '''\n",
        "    The WER is defined as the edit/Levenshtein distance on word level divided by\n",
        "    the amount of words in the original text.\n",
        "    In case of the original having more words (N) than the result and both\n",
        "    being totally different (all N words resulting in 1 edit operation each),\n",
        "    the WER will always be 1 (N / N = 1).\n",
        "    '''\n",
        "    error_rate = (item[unit+'_dist'] / item[unit+'_len'])\n",
        "    return error_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zdEOl3udFv6L"
      },
      "outputs": [],
      "source": [
        "def get_levenshtein_distance(item, unit):\n",
        "    '''\n",
        "    unit is either char or word\n",
        "    '''\n",
        "    # lowercase both ground-truth and prediction and remove punctuation\n",
        "    # for calculation of edit distance\n",
        "    ground_truth = item['sentence'].lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    prediction = item['prediction'].lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    distance = 0;\n",
        "    if unit == 'word':\n",
        "        distance = levenshtein(ground_truth.split(), prediction.split())\n",
        "    elif unit == 'char':\n",
        "        distance = levenshtein(ground_truth, prediction)\n",
        "    else:\n",
        "        print('ERROR: must be word or char')\n",
        "\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OlRIQMzlIPKD"
      },
      "outputs": [],
      "source": [
        "def get_merged_df(artie_bias_file, prediction_file):\n",
        "    # Import the ground-truth transcripts and demographic tags\n",
        "    ground_truth_df = pd.read_csv(artie_bias_file, delimiter='\\t')\n",
        "    if not ground_truth_df.columns.tolist() == ['client_id', 'path', 'sentence',\n",
        "                                                'up_votes', 'down_votes', 'age',\n",
        "                                                'gender', 'accent']:\n",
        "        print(\"\\n### ERROR: Your ARTIE_CORPUS TSV file does not have the correct column structure.\\n\")\n",
        "        exit(1)\n",
        "    else:\n",
        "        ground_truth_df['path'] = ground_truth_df['path'].apply(lambda path: os.path.splitext(path)[0])\n",
        "\n",
        "    prediction_df = pd.read_csv(prediction_file, delimiter='\\t')\n",
        "    if not prediction_df.columns.tolist() == ['path','prediction']:\n",
        "        print(\"\\n### ERROR: Your PREDICTIONS TSV file does not have the correct column structure.\\n\")\n",
        "        exit(1)\n",
        "    else:\n",
        "        prediction_df['path'] = prediction_df['path'].apply(lambda path: os.path.splitext(path)[0])\n",
        "        prediction_df['prediction'].fillna(\"\", inplace=True)\n",
        "    \n",
        "    # Merge ground-truth (which has demographic data) and predictions\n",
        "    pred_df = pd.merge(left=ground_truth_df,\n",
        "                  right=prediction_df,\n",
        "                  left_on='path',\n",
        "                  right_on='path')\n",
        "    # calculate utterance-level statistics\n",
        "    if unit == 'word':\n",
        "        pred_df[unit+'_len'] = pred_df['sentence'].str.split().str.len()\n",
        "    elif unit == 'char':\n",
        "        pred_df[unit+'_len'] = pred_df['sentence'].str.len()\n",
        "    pred_df[unit+'_dist'] = pred_df.apply(get_levenshtein_distance, axis=1, unit=unit)\n",
        "    pred_df[unit+'_error_rate'] = pred_df.apply(get_error_rate, axis=1, unit=unit)\n",
        "\n",
        "    return pred_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VwPUeOA-ITeC"
      },
      "outputs": [],
      "source": [
        "def get_demographic_class(demographic):\n",
        "    if demographic in ['male','female']:\n",
        "        return \"gender\"\n",
        "        \n",
        "    elif demographic in ['african','australia','bermuda','canada','england',\n",
        "                         'hongkong','indian','ireland','malaysia','newzealand',\n",
        "                         'philippines','scotland','singapore','southatlandtic',\n",
        "                         'us','wales']:\n",
        "        return \"accent\"\n",
        "        \n",
        "    elif demographic in ['teens','twenties','thirties', 'fourties', 'fifties',\n",
        "                         'sixties', 'seventies', 'eighties', 'nineties']:\n",
        "        return \"age\"\n",
        "        \n",
        "    else:\n",
        "        print(\"ERROR: your requested demographic:\", demographic, \" is not a default, please check spelling or add it to this script.\")\n",
        "        print(\"Here is the list of demographics in the Artie Bias Corpus:\",\n",
        "              ['male','female','african','australia','bermuda','canada',\n",
        "               'england','hongkong','indian','ireland','malaysia','newzealand',\n",
        "               'philippines','scotland','singapore','southatlandtic',\n",
        "               'us','wales','teens','twenties','thirties', 'fourties', 'fifties',\n",
        "               'sixties', 'seventies', 'eighties', 'nineties'])\n",
        "        exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7ogKIOxYIUHB"
      },
      "outputs": [],
      "source": [
        "def compare_two_models(unit, demographic, pred_dfs):\n",
        "    '''\n",
        "    run the main program\n",
        "    '''\n",
        "\n",
        "    demographic_class = get_demographic_class(demographic)\n",
        "        \n",
        "    groups=[]\n",
        "    for i,df in enumerate(pred_dfs):\n",
        "        errors=df[df[demographic_class] == demographic][unit+'_error_rate']\n",
        "        groups.append(errors)\n",
        "        print(\"\\n###\", demographic, unit, \"error rate on\" ,\"for model\", i, \"=\", np.mean(errors),\n",
        "              \"( for\", len(errors), \"audio clips )\")\n",
        "        \n",
        "    print(\"\\n###\", \"one-way ANOVA result:\", stats.f_oneway(groups[0], groups[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bM_y9nDFIW9j"
      },
      "outputs": [],
      "source": [
        "def detect_bias_in_one_model(unit, demographics, pred_df):\n",
        "    '''\n",
        "    run the main program\n",
        "    '''\n",
        "\n",
        "    groups=[]\n",
        "    for demographic in demographics:\n",
        "        demographic_class = get_demographic_class(demographic)\n",
        "        errors=pred_df[pred_df[demographic_class] == demographic][unit+'_error_rate']\n",
        "        groups.append(errors)\n",
        "        print(\"\\n###\", demographic, unit, \"error rate =\", np.mean(errors),\n",
        "              \"( for\", len(errors), \"audio clips )\")\n",
        "\n",
        "    print(\"\\n###\", \"one-way ANOVA result:\", stats.f_oneway(groups[0], groups[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BeeKO5HXIZkd"
      },
      "outputs": [],
      "source": [
        "def plot_demographic_error(df, unit, demographic, user_file):  \n",
        "    '''\n",
        "    create a bar plot along a certain demographic, according to\n",
        "    either CER or WER\n",
        "    run the main program\n",
        "    '''\n",
        "\n",
        "    demographic_class = get_demographic_class(demographic)\n",
        "    \n",
        "    demo_df = df.groupby([demographic_class])[[unit+'_dist', unit+'_len']].sum()\n",
        "    demo_df[unit+'_error_rate'] = demo_df.apply(get_error_rate, axis=1, unit=unit)\n",
        "    ax = demo_df.sort_values(unit+'_error_rate').plot.bar(y=unit+'_error_rate', rot=0)\n",
        "    plt.title('Effect of *' + demographic_class.upper() + '* on '\n",
        "              + unit.upper() + ' Error Rate in ' + user_file.upper())\n",
        "    plt.ylabel('Average Percentage (%) ' + unit +'_error_rate' + ' for Population')\n",
        "    plt.xlabel(demographic_class + ' of Talker')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uFDib0rhIbTN"
      },
      "outputs": [],
      "source": [
        "def print_args_error(error):\n",
        "    print(\"\\n\",\"ERROR: `detect_bias.py` requires **three** positional arguments, at least one of them is\", error) \n",
        "\n",
        "    print(\n",
        "        '''\n",
        "        Usage: detect_bias.py ARTIE_CORPUS PREDICTIONS DEMOGRAPHIC\n",
        "        \n",
        "        ARTIE_CORPUS: string: the path to the artie-bias-corpus.tsv file provided in this repo under data/.\n",
        "        PREDICTIONS:  string: prediction TSV(s) for the models you wish to compare. If more than one, then comma-separated\n",
        "        DEMOGRAPHIC:  string: the demographic(s) used for comparison.  If more than one, then comma-separated\n",
        "                              ['male', 'female', 'indian', 'england', 'twenties', \n",
        "                               'thirties', etc. - consult the README for a full list]\n",
        "        e.g.:  $ ./detect_bias.py \"artie-bias-corpus.tsv\" \"your-model-predictions.tsv\" \"male,female\"\n",
        "        '''\n",
        "        #UNIT:         string: 'word' for Word Error Rate comparison, and 'char' for Character Error Rate comparison.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KmnfHHSDIdui"
      },
      "outputs": [],
      "source": [
        "def check_args(user_files,artie_data,unit,demographics):\n",
        "    '''\n",
        "    a function to check all the input arguments and throw errors if needed\n",
        "    '''\n",
        "    if len(user_files)>2:\n",
        "        print('''\n",
        "        ERROR: You are trying to compare more than two models. \n",
        "               This is not currently supported. You should make changes\n",
        "               to the main() function call to suit your needs.\n",
        "              ''')\n",
        "        exit(1)\n",
        "    bool_exist=[os.path.isfile(i) for i in user_files]\n",
        "    bool_exist.append(os.path.isfile(artie_data))\n",
        "    if sum(bool_exist)<(len(user_files)+1):\n",
        "        print(\"Provided Args: \", artie_data, unit, user_files, demographics)\n",
        "        print_args_error(\"invalid\")\n",
        "        exit(1)\n",
        "    if not (unit in [\"char\",\"word\"]):\n",
        "        print('ERROR: unit must be either \"char\" or \"word\", not', unit)\n",
        "        exit(1)\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oMfAh4ruIfn7"
      },
      "outputs": [],
      "source": [
        "artie_data = None\n",
        "user_files = None\n",
        "demographics = None\n",
        "unit = \"\"\n",
        "def detect_bias(artie_annotation,yhat,demos,vizualize):\n",
        "    import os\n",
        "    global artie_data\n",
        "    global user_files\n",
        "    global demographics\n",
        "    global unit\n",
        "    try:\n",
        "        artie_data = artie_annotation\n",
        "        user_files = [ i.strip() for i in str(yhat).split(\",\") ]\n",
        "        demographics = [ i.strip() for i in str(demos).split(\",\") ]\n",
        "        unit = \"word\" # TODO make this an optional CL arg\n",
        "    except IndexError:\n",
        "        print_args_error(\"missing\")\n",
        "        exit(1)\n",
        "\n",
        "    check_args(user_files,artie_data,unit,demographics)  \n",
        "    ## COMPARE TWO DEMOGRAPHICS\n",
        "    if len(demographics)>1 and len(user_files)==1:\n",
        "        print(\"BEGIN BIAS DETECTION in\", user_files[0])\n",
        "        \n",
        "        pred_df = get_merged_df(artie_data, user_files[0])\n",
        "        detect_bias_in_one_model(unit, demographics, pred_df)\n",
        "        pred_dfs=[pred_df]\n",
        "        \n",
        "    ### COMPARE TWO MODELS\n",
        "    elif len(demographics)==1 and len(user_files)>1:\n",
        "        print(\"BEGIN MODEL COMPARISON of\", user_files)\n",
        "        \n",
        "        pred_dfs = [ get_merged_df(artie_data, user_file)\n",
        "                     for user_file in user_files]\n",
        "        compare_two_models(unit, demographics[0], pred_dfs)\n",
        "\n",
        "    else:\n",
        "        print('''\n",
        "        ERROR: Currently you can only compare two models \n",
        "               along one demographic line, or one model along two demographics.\n",
        "               If you want to do something else you can make changes to the code.\n",
        "        ''')\n",
        "        exit(1)\n",
        "\n",
        "    if vizualize:\n",
        "        for i,pred_df in enumerate(pred_dfs):\n",
        "            \n",
        "            plot_demographic_error(pred_df,unit,demographics[0],user_files[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIiCOKthC_pu",
        "outputId": "8e6b54b7-b7c5-45bf-f876-b6e59d4cf9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEGIN BIAS DETECTION in tsv_files/deepSpeech.tsv\n",
            "\n",
            "### indian word error rate = 0.7321428571428572 ( for 2 audio clips )\n",
            "\n",
            "### us word error rate = 0.5347222222222222 ( for 2 audio clips )\n",
            "\n",
            "### one-way ANOVA result: F_onewayResult(statistic=0.20121130209894675, pvalue=0.6976602018820867)\n"
          ]
        }
      ],
      "source": [
        "detect_bias('tsv_files/ourAnnot.tsv','tsv_files/deepSpeech.tsv','indian,us',False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgwFmutkwsbr"
      },
      "source": [
        "## Validating a claim\n",
        "\n",
        "---\n",
        "\n",
        "As stated earlier in this notebook, we wanted to test a claim that was stated in [7] that proved whether or not the DeepSpeech algorithm was biased based on the accent of the speaker. In most cases, this seems to be male American accents due to the overwhelming presence in the testing of voice recognition engines in the US. The claim that we are choosing to validate is as follows:  \n",
        "\n",
        "**Claim**: DeepSpeech, an existing large text-to-speech model, is biased on accent of the speaker. You could validate this claim by trying out DeepSpeech on some carefully selected \"new\" test samples and annotating the results yourself.\n",
        "\n",
        "In this respect, we are testing information that has been proved in two figures in [7], both of which are in the Background section of this notebook, to see if DeepSpeech is indeed biased towards American accents, seemingly with gender not being a prime factor. This would be an interesting claim to make as the Artie Bias Corpus data has tested around 1700 audio samples voluntarily sampled from people, with annotations of the actual sentences. Various .tsv files are in the repository tested with different voice recognition engines were also included, with success varying from one engine to the next. For this notebook, we primarily used the DeepSpeech algorithm and recorded the predictions in another .tsv file and compared that to the actual sentence said and determined how accurate DeepSpeech is and where the bias lies.\n",
        "\n",
        "Resources that were used for the claim validation included university lectures found on YouTube, where we had to gather two of each accent that we decided to use (American, British, Scottish, Australian, and Indian). Then we had to get the audio samples from those lectures made in a specific timeframe (usually within the first 30 seconds of a video), and then get the predictions with the algorithm. Then we record the predictions in another .tsv file for comparison. Based on the results that we obtained, we will then determine how biased the system is, and whether one person's accent impairs the ability of voice recoginition tools to properly determine what he or she is saying.\n",
        "\n",
        "In our case, we decided to test out DeepSpeech's prediction system using the audio samples after conversion, annotation and putting them through the algorithm. In the cell above, we see that the comparison is made between two .tsv files, one with the actual sentences and another with prediction as it is loaded into this notebook. We decided to test it out using 2 samples each from the American and Indian Professors' accents, though all of the audio has been sampled from the first 30 seconds of each lecture. After annotating and predicting the text with DeepSpeech, we compared the error rate to see if they can be reproduced. In our findings in one of those instances, we see that the word error rates for Indian accents is much higher than American ones, meaning that voice recognition engines have a harder time understanding what is being said from those with Indian accents. Next we decided to compare the error rates between male and female speakers to see if the error rates are comparable, as in being around 5% within each other. Below is the cell for comparison of American and British accents, and another with both male and female speakers.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ6IzEQdwftn",
        "outputId": "ef13cdac-dd6c-4624-97d3-de1296b2d82b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEGIN BIAS DETECTION in tsv_files/deepSpeech.tsv\n",
            "\n",
            "### male word error rate = 0.765951642641449 ( for 7 audio clips )\n",
            "\n",
            "### female word error rate = 0.6802503052503052 ( for 3 audio clips )\n",
            "\n",
            "### one-way ANOVA result: F_onewayResult(statistic=0.18853683778459493, pvalue=0.6756101225293828)\n"
          ]
        }
      ],
      "source": [
        "detect_bias('tsv_files/ourAnnot.tsv','tsv_files/deepSpeech.tsv','male,female',False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm3N_sBct4Mq"
      },
      "source": [
        "---\n",
        "\n",
        "In the cell above, we see that although we could only compare the male and female audio samples from the .tsv files that we already tested. We see that in comparison to the American and Indian accent speakers where the error rate was a giant gap, the gender bias gap isn't as large, although it still favors female speakers, likely because there's more audio clips collected from them. The error rate is closer than the previous collection, still proving that the gender bias isn't as noticable as the accent of the speaker, but slightly bigger than anticipated. For curiousity's sake, we'll test the error rates in both Scottish and Australian speakers to see how well they would stack up compared to the others.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfj5wVh53pxh",
        "outputId": "519447e2-6efb-46bb-d98a-5101a23a32be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEGIN BIAS DETECTION in tsv_files/deepSpeech.tsv\n",
            "\n",
            "### scotland word error rate = 0.7559523809523809 ( for 2 audio clips )\n",
            "\n",
            "### australia word error rate = 0.7926421404682273 ( for 2 audio clips )\n",
            "\n",
            "### one-way ANOVA result: F_onewayResult(statistic=0.4643564471488748, pvalue=0.5659158010522445)\n"
          ]
        }
      ],
      "source": [
        "detect_bias('tsv_files/ourAnnot.tsv','tsv_files/deepSpeech.tsv','scotland,australia',False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Ynd2UY4FuO"
      },
      "source": [
        "---\n",
        "\n",
        "Here we see that the error rates for Scottish and Australian speakers is relatively high compared to other demographics, as the DeepSpeech algorithm in the Artie Bias Corpus likely isn't as well trained on either accent, with the closest comparison being British accented speakers. As it can be seen, the error rates are relatively similar, with little difference between the two for DeepSpeech to understand them. Overall, we can say that although there seems to be little in terms of gender bias, the accent of the speaker does make a difference for the DeepSpeech algorithm to understand the users. Thus we can say that the bias can interfere with voice recognition, proving the claim that was made earlier is true, meaning that DeepSpeech is biased on the accent on the speaker, favoring American accents more than anything else.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIZM2e1Swt9Q"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpNSLq16D5bs"
      },
      "source": [
        "Note that References 10-19 are used for creating the voices samples we used for annotations and predictions using DeepSpeech for our .tsv files\n",
        "\n",
        "[1] Mozilla. \"Project DeepSpeech.\" GitHub. https://github.com/mozilla/DeepSpeech (Accessed December 6, 2022)\n",
        "\n",
        "[2] M. Shkhanukova. \"ASR state-of-the-art: Wav2Vec, Whisper, DeepSpeech.\" Medium. https://medium.com/@milana.shxanukova15/asr-state-of-the-art-wav2vec-whisper-deepspeech-e1b715c2aed0 (Accessed December 6, 2022)\n",
        "\n",
        "[3] A. Talasila. \"Generate Subtitles for any video file using Mozilla DeepSpeech.\" Towards Data Science. https://towardsdatascience.com/generating-subtitles-automatically-using-mozilla-deepspeech-562c633936a7 (Accessed December 6, 2022)\n",
        "\n",
        "[4] K. Wiggers. \"Artie releases tool to measure bias in speech recognition models.\" VentureBeat. https://venturebeat.com/ai/artie-releases-tool-to-measure-bias-in-speech-recognition-models/ (Accessed December 6, 2022)\n",
        "\n",
        "[5] R. Horrigan. \"Announcing The Artie Bias Corpus: a speech dataset for bias detection in voice applications.\" LinkedIn. https://www.linkedin.com/pulse/announcing-artie-bias-corpus-speech-dataset-detection-ryan-horrigan/ (Accessed December 6, 2022)\n",
        "\n",
        "[6] Artie Inc. \"Artie Bias Corpus + Tools.\" GitHub. https://github.com/artie-inc/artie-bias-corpus (Accessed December 6, 2022)\n",
        "\n",
        "[7] J. Meyer et al. \"Artie Bias Corpus: An Open Dataset for Detecting Demographic Bias in Speech\n",
        "Applications.\" Artie, Inc. https://aclanthology.org/2020.lrec-1.796.pdf (Accessed December 6, 2022)\n",
        "\n",
        "[8] tugstugi. \"Speech Recognition with DeepSpeech.\" Google Colab. https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/MozillaDeepSpeech.ipynb?authuser=2#scrollTo=3KUlO4oiA8CM (Accessed December 7, 2022)\n",
        "\n",
        "[9] R. LIN. \"Convert Video/Audio to Text with Mozilla DeepSpeech.\" Medium. https://reneelin2019.medium.com/video-audio-to-text-with-mozilla-deepspeech-2f7c3b3aef1f (Accessed December 9, 2022)\n",
        "\n",
        "[10] University of Oxford. \"Oxford London Lecture 2012: \"21st Century -- The Last Century of Youth\"\". YouTube. https://www.youtube.com/watch?v=G3L9XOHqzak (May 13, 2012). (Accessed December 6, 2022)\n",
        "\n",
        "[11] University of Birmingham. \"Professor John Curtice - How has Brexit reshaped British politics? (full lecture)\". YouTube. https://www.youtube.com/watch?v=eTwCZ6oifFQ (October 16, 2017). (Accessed December 6, 2022)\n",
        "\n",
        "[12] YaleCourses. \"Lecture 1: Introduction to Power and Politics in Todays World\". YouTube. https://www.youtube.com/watch?v=BDqvzFY72mg (September 17, 2019). (Accessed December 7, 2022)\n",
        "\n",
        "[13] CosmoLearning. \"Harvard ENGL E-129 - Lecture 1: Introduction\". YouTube. https://www.youtube.com/watch?v=A0mFFJJLM2M (January 18, 2015). (Accessed December 7, 2022)\n",
        "\n",
        "[14] UNSW Community. \"The Inaugural Patrick O'Farrell Memorial Lecture - Professor David Fitzpatrick: Australia's Irish Qu\". YouTube. https://www.youtube.com/watch?v=ExZRHM1Zu_A (December 15, 2011). (Accessed December 7, 2022)\n",
        "\n",
        "[15] Virginia University of Wellington. \"PUBLIC LECTURE: 'How to defend New Zealand' | Professor Hugh White, Australian National University\". YouTube. https://www.youtube.com/watch?v=_4B-JZQG9FA (September 12, 2019). (Accessed December 7, 2022)\n",
        "\n",
        "[16] Centre for Scottish Culture. \"History Scotland Lecture 1: Who were the Jacobites and what did they want for Scotland?\". YouTube. https://www.youtube.com/watch?v=0_zXZz0Jar8 (May 14, 2018). (Accessed December 7, 2022)\n",
        "\n",
        "[17] Robert Gordon University. \"Professorial Lectures 2019: Professor Rhona Flin\". YouTube. https://www.youtube.com/watch?v=UyphlSA6zfE (April 3, 2019). (Accessed December 7, 2022)\n",
        "\n",
        "[18] Vinay Lal. \"Indian Civilization [Lec 01]\". YouTube. https://www.youtube.com/watch?v=93JMjX1XECo (September 2, 2013). (Accessed December 7, 2022)\n",
        "\n",
        "[19] FICCI India. \"#FICCIat90 Leadership Lecture Series | Prof Ram Charan\". YouTube. https://www.youtube.com/watch?v=VhMdSQrGbY0 (July 27, 2017). (Accessed December 7, 2022)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
